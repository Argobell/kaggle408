{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"/root/autodl-tmp/kaggle408/checkpoints/gek_e2b\", \n",
    "    max_seq_length = 4096, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    attn_implementation = \"eager\", # necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b8cba",
   "metadata": {},
   "source": [
    "<img src=\"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\" alt=\"Alt text\" height=\"256\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714cc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sloth_link = \"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\"\n",
    "\n",
    "messages = [{\n",
    "    \"role\" : \"user\",\n",
    "    \"content\": [\n",
    "        { \"type\": \"image\", \"image\" : sloth_link },\n",
    "        { \"type\": \"text\",  \"text\" : \"Which films does this animal feature in?\" }\n",
    "    ]\n",
    "}]\n",
    "\n",
    "messages = tokenizer.apply_chat_template(messages).removeprefix('<bos>')\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "train_set = load_dataset(\"/root/autodl-tmp/kaggle408/dataset/rlaif-v\",split=\"train[:20%]\")\n",
    "eval_set = load_dataset(\"/root/autodl-tmp/kaggle408/dataset/rlaif-v\",split=\"train[99.5%:]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e73878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(example):\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": example[\"question\"]}],\n",
    "        },\n",
    "    ]\n",
    "    chosen = [\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": example[\"chosen\"]}],\n",
    "        },\n",
    "    ]\n",
    "    rejected = [\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": example[\"rejected\"]}],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    max_size = max(tokenizer.image_processor.size.values())\n",
    "    example[\"image\"].thumbnail((max_size, max_size))\n",
    "\n",
    "    if isinstance(example[\"image\"], Image.Image) and example[\"image\"].mode != \"RGB\":\n",
    "        example[\"image\"] = example[\"image\"].convert(\"RGB\")\n",
    "\n",
    "    return {\"images\": [example[\"image\"]], \"prompt\": prompt, \"chosen\": chosen, \"rejected\": rejected}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.map(format, remove_columns=train_set.column_names)\n",
    "eval_set = eval_set.map(format, remove_columns=eval_set.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True, # Turn off for just text!\n",
    "    finetune_language_layers   = True,  # Should leave on!\n",
    "    finetune_attention_modules = True,  # Attention good for GRPO\n",
    "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
    "\n",
    "    r = 8,           # Larger = higher accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e61f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swanlab.integration.transformers import SwanLabCallback\n",
    "swanlab_callback = SwanLabCallback(\n",
    "    project=\"kaggle408\",\n",
    "    experiment_name=\"gemma3n-mutlti-dpo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import PatchDPOTrainer\n",
    "\n",
    "PatchDPOTrainer()\n",
    "\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model = model,\n",
    "    ref_model = None,\n",
    "    callbacks=[swanlab_callback],\n",
    "    args = DPOConfig(\n",
    "        gradient_checkpointing=True,\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 1,\n",
    "        learning_rate = 5e-6,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.0,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        dataloader_num_workers=8,\n",
    "        dataset_num_proc=8,\n",
    "    ),\n",
    "    processing_class= tokenizer.tokenizer,\n",
    "    beta = 0.1,\n",
    "    train_dataset = train_set,\n",
    "    eval_dataset = eval_set,\n",
    "    max_length = 2048,\n",
    "    max_prompt_length = 512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle408",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
