{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3c1901",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"/root/autodl-tmp/model/gemma3n_E2B\", # gemma3n-e2b:5B gemma3n-e4b:8B\n",
    "    max_seq_length = 1024, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    attn_implementation = \"eager\", # necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441eaf9d",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a4732",
   "metadata": {},
   "source": [
    "**Inputs and Outputs**\n",
    "\n",
    "**Inputs**  \n",
    "- Text string (question, prompt, document to summarize)  \n",
    "- Images, normalized to 256×256, 512×512, or 768×768 and encoded to 256 tokens each  \n",
    "- Audio data, single-channel, encoded to 6.25 tokens per second  \n",
    "- Total input context: 32 K tokens  \n",
    "\n",
    "**Outputs**  \n",
    "- Generated text (answer, image analysis, document summary, etc.)  \n",
    "- Total output length: up to 32 K tokens, minus the request input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "import gc\n",
    "\n",
    "# Helper function for inference\n",
    "def gemma3n_inference(model, messages, max_new_tokens = 128):\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt = True, # Must add for generation\n",
    "        tokenize = True,\n",
    "        return_dict = True,\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "    _ = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        temperature = 1.0, top_p = 0.95, top_k = 64,\n",
    "        streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    "    )\n",
    "    # Cleanup to reduce VRAM usage\n",
    "    del inputs\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08955691",
   "metadata": {},
   "source": [
    "### Image-Text-to-Text Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f670da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_image_with_aspect_ratio(image: Image.Image, max_size: int) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Resizes an image to a maximum size while maintaining aspect ratio.\n",
    "\n",
    "    Args:\n",
    "        image (Image.Image): The PIL Image object.\n",
    "        max_size (int): The maximum dimension (width or height).\n",
    "\n",
    "    Returns:\n",
    "        Image.Image: The resized PIL Image object.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    if width > max_size or height > max_size:\n",
    "        if width > height:\n",
    "            new_width = max_size\n",
    "            new_height = int(height * (max_size / width))\n",
    "        else:\n",
    "            new_height = max_size\n",
    "            new_width = int(width * (max_size / height))\n",
    "        return image.resize((new_width, new_height))\n",
    "    return image\n",
    "\n",
    "image = Image.open(\"/root/autodl-tmp/kaggle408/resources/question_goose.png\")\n",
    "image = resize_image_with_aspect_ratio(image, 512)\n",
    "display(image)\n",
    "print(f\"Image Size:{image.size}, Type:{type(image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799042b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\" : \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"image\", \"image\": image},\n",
    "        { \"type\": \"text\",  \"text\" : \"Describe this image in detail.\" }\n",
    "    ]\n",
    "}]\n",
    "# You might have to wait 1 minute for Unsloth's auto compiler\n",
    "gemma3n_inference(model, messages, max_new_tokens = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a79f7",
   "metadata": {},
   "source": [
    "### Text Generation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff18e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\" : \"user\",\n",
    "    \"content\": [\n",
    "        { \"type\": \"text\",  \"text\" : \"Who are you?\" }\n",
    "    ]\n",
    "}]\n",
    "\n",
    "gemma3n_inference(model, messages, max_new_tokens = 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle408",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
